version: '3'

services:
  postgres:
    image: postgres:14
    container_name: postgres_breweries
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data

  spark:
    build:
      context: .
      dockerfile: src/Dockerfile
    container_name: src_breweries
    volumes:
      - ./src:/app
      - ./volumes/warehouse:/warehouse
    depends_on:
      - postgres
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}   # nome do serviço Postgres no docker-compose
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "4040:4040"
    entrypoint: ["sleep", "infinity"]

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_init_breweries
    restart: unless-stopped
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/plugins
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: ${AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT}
      POSTGRES_HOST: ${POSTGRES_HOST}   # nome do serviço Postgres no docker-compose
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      PYTHONPATH: /app
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/app
      - ./jars:/opt/bitnami/spark/jars
    command: >
      bash -c "
        until pg_isready -h ${POSTGRES_HOST} -p ${POSTGRES_PORT}; do
          echo 'Waiting for Postgres...';
          sleep 2;
        done &&
        airflow db migrate &&
        airflow connections create-default-connections &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_webserver_breweries
    restart: on-failure
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/plugins
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__LOGGING__LOGGING_LEVEL: DEBUG
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: ${AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT}
      POSTGRES_HOST: ${POSTGRES_HOST}   # nome do serviço Postgres no docker-compose
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      PYTHONPATH: /app
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/app
      - ./volumes/warehouse:/warehouse
      - ./requirements.txt:/requirements.txt
      - ./jars:/opt/bitnami/spark/jars
    ports:
      - "8080:8080"
    command: >
      bash -c "
        until pg_isready -h ${POSTGRES_HOST} -p ${POSTGRES_PORT}; do
          echo 'Waiting for Postgres...';
          sleep 2;
        done &&
        airflow webserver
      "
    depends_on:
      - postgres
      - airflow-init

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_scheduler_breweries
    restart: on-failure
    depends_on:
      - airflow-webserver
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/plugins
      AIRFLOW__LOGGING__LOGGING_LEVEL: DEBUG
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: ${AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT}
      POSTGRES_HOST: ${POSTGRES_HOST}   # nome do serviço Postgres no docker-compose
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      PYTHONPATH: /app
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/app
      - ./volumes/warehouse:/warehouse
      - ./jars:/opt/bitnami/spark/jars
    command: >
      bash -c "
        until pg_isready -h ${POSTGRES_HOST} -p ${POSTGRES_PORT}; do
          echo 'Waiting for Postgres...';
          sleep 2;
        done &&
        airflow scheduler"
  test-runner:
    build:
      context: .
      dockerfile: Dockerfile.test
    volumes:
      - .:/app
    container_name: test_breweries
    restart: on-failure
    environment:
      PYTHONPATH: /app
    depends_on:
      - spark
    command: ["pytest", "unit_tests"]

volumes:
  pg_data: